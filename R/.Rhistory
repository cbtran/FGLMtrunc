# Z-value vector
z <- c(z.null, z.non.null)
z.true <- c(rep(0,num.null), non.null.true)
z.true.01 <- c(rep(0,num.null), rep(1, num.non.null))
# Test example
test <- multiple_testing(z, q.level=0.2, method="BH") # choose BH since tests are independently generated
#False discovery proportion
fp <- sum(test$rej.hypo.vec==1 & z.true.01==0)
fdp[i] <- mean( fp / max(1,test$num.reject))
#False coverage proportion
fcp[i] <- mean(sum((test$rejection.conf.int$conf.lower > z.true[test$rej.hypo.vec.index]) |
(test$rejection.conf.int$conf.upper < z.true[test$rej.hypo.vec.index])) / max(1,test$num.reject))
}
#False discovery rate is average of false discovery proportion
fdr <- mean(fdp)
fdr
#False coverage rate is average of false coverage proportion
mean(fcp)
# test$num.reject
# plot(fdp, fcp)
# abline(0, 1)
multiple_testing <- function(z.value.vector, q.level = 0.05, method=c("BY", "BH")) {
# Get p-values vector
p.value.vector <- 2*pnorm(abs(z.value.vector), lower.tail = F)
num.test <- length(p.value.vector)
# Get adjusted p-values vector
p.value.vector.adjusted <- p.adjust(p.value.vector, method=method)
# Rejected hypotheses vector
rej.hypo.vec <- p.value.vector.adjusted < q.level
rej.hypo.vec.index <- which(rej.hypo.vec == 1)
# Number of rejection
R <- sum(rej.hypo.vec)
# Z.value for confidence interval
Z.value <- qnorm(1 - R*q.level/num.test, mean = 0, sd = 1, lower.tail = TRUE, log.p = FALSE)
conf.lower.vector <- z.value.vector[rej.hypo.vec.index] - Z.value
conf.upper.vector <- z.value.vector[rej.hypo.vec.index] + Z.value
returns <- list()
df <- data.frame(test.index = rej.hypo.vec.index,
z.value = z.value.vector[rej.hypo.vec.index],
conf.lower = conf.lower.vector,
conf.upper = conf.upper.vector,
p.value = p.value.vector[rej.hypo.vec.index],
p.value.adjusted = p.value.vector.adjusted[rej.hypo.vec.index]
)
returns$rejection.conf.int <- df
returns$rej.hypo.vec <- rej.hypo.vec
returns$num.reject <- R
returns$rej.hypo.vec.index <- rej.hypo.vec.index
return(returns)
}
# Test with simulated z
num.rep <- 100
num.test <- 1000
#Numbers of non-null
num.non.null <- floor(num.test/10)
#Numbers of null
num.null <- num.test - num.non.null
# false discovery proportion vector
fdp <- rep(NA,num.rep )
# false coverage proportion vector
fcp <- rep(NA,num.rep )
for (i in 1:num.rep) {
# Z-value with true mu = 0
z.null <- rnorm(num.null)
# Z-value with true mu != 0
non.null.true <- rnorm(num.non.null, mean=-3,sd=1)
z.non.null <- non.null.true + rnorm(num.non.null)
# Z-value vector
z <- c(z.null, z.non.null)
z.true <- c(rep(0,num.null), non.null.true)
z.true.01 <- c(rep(0,num.null), rep(1, num.non.null))
# Test example
test <- multiple_testing(z, q.level=0.2, method="BH") # choose BH since tests are independently generated
#False discovery proportion
fp <- sum(test$rej.hypo.vec==1 & z.true.01==0)
fdp[i] <- mean( fp / max(1,test$num.reject))
#False coverage proportion
fcp[i] <- mean(sum((test$rejection.conf.int$conf.lower > z.true[test$rej.hypo.vec.index]) |
(test$rejection.conf.int$conf.upper < z.true[test$rej.hypo.vec.index])) / max(1,test$num.reject))
}
#False discovery rate is average of false discovery proportion
fdr <- mean(fdp)
fdr
#False coverage rate is average of false coverage proportion
mean(fcp)
# test$num.reject
# plot(fdp, fcp)
# abline(0, 1)
multiple_testing <- function(z.value.vector, q.level = 0.05, method=c("BY", "BH")) {
# Get p-values vector
p.value.vector <- 2*pnorm(abs(z.value.vector), lower.tail = F)
num.test <- length(p.value.vector)
# Get adjusted p-values vector
p.value.vector.adjusted <- p.adjust(p.value.vector, method=method)
# Rejected hypotheses vector
rej.hypo.vec <- p.value.vector.adjusted < q.level
rej.hypo.vec.index <- which(rej.hypo.vec == 1)
# Number of rejection
R <- sum(rej.hypo.vec)
# Z.value for confidence interval
Z.value <- qnorm(1 - R*q.level/num.test, mean = 0, sd = 1, lower.tail = TRUE, log.p = FALSE)
conf.lower.vector <- z.value.vector[rej.hypo.vec.index] - Z.value
conf.upper.vector <- z.value.vector[rej.hypo.vec.index] + Z.value
returns <- list()
df <- data.frame(test.index = rej.hypo.vec.index,
z.value = z.value.vector[rej.hypo.vec.index],
conf.lower = conf.lower.vector,
conf.upper = conf.upper.vector,
p.value = p.value.vector[rej.hypo.vec.index],
p.value.adjusted = p.value.vector.adjusted[rej.hypo.vec.index]
)
returns$rejection.conf.int <- df
returns$rej.hypo.vec <- rej.hypo.vec
returns$num.reject <- R
returns$rej.hypo.vec.index <- rej.hypo.vec.index
return(returns)
}
# Test with simulated z
num.rep <- 100
num.test <- 1000
#Numbers of non-null
num.non.null <- floor(num.test/10)
#Numbers of null
num.null <- num.test - num.non.null
# false discovery proportion vector
fdp <- rep(NA,num.rep )
# false coverage proportion vector
fcp <- rep(NA,num.rep )
for (i in 1:num.rep) {
# Z-value with true mu = 0
z.null <- rnorm(num.null)
# Z-value with true mu != 0
non.null.true <- rnorm(num.non.null, mean=-3,sd=1)
z.non.null <- non.null.true + rnorm(num.non.null)
# Z-value vector
z <- c(z.null, z.non.null)
z.true <- c(rep(0,num.null), non.null.true)
z.true.01 <- c(rep(0,num.null), rep(1, num.non.null))
# Test example
test <- multiple_testing(z, q.level=0.1, method="BH") # choose BH since tests are independently generated
#False discovery proportion
fp <- sum(test$rej.hypo.vec==1 & z.true.01==0)
fdp[i] <- mean( fp / max(1,test$num.reject))
#False coverage proportion
fcp[i] <- mean(sum((test$rejection.conf.int$conf.lower > z.true[test$rej.hypo.vec.index]) |
(test$rejection.conf.int$conf.upper < z.true[test$rej.hypo.vec.index])) / max(1,test$num.reject))
}
#False discovery rate is average of false discovery proportion
fdr <- mean(fdp)
fdr
#False coverage rate is average of false coverage proportion
mean(fcp)
# FDR and FCR should be smaller than q.level (slightly violation may due to monte carlo error)
# test$num.reject
# plot(fdp, fcp)
# abline(0, 1)
multiple_testing <- function(z.value.vector, q.level = 0.05, method=c("BY", "BH")) {
# Get p-values vector
p.value.vector <- 2*pnorm(abs(z.value.vector), lower.tail = F)
num.test <- length(p.value.vector)
# Get adjusted p-values vector
p.value.vector.adjusted <- p.adjust(p.value.vector, method=method)
# Rejected hypotheses vector
rej.hypo.vec <- p.value.vector.adjusted < q.level
rej.hypo.vec.index <- which(rej.hypo.vec == 1)
# Number of rejection
R <- sum(rej.hypo.vec)
# Z.value for confidence interval
Z.value <- qnorm(1 - R*q.level/num.test, mean = 0, sd = 1, lower.tail = TRUE, log.p = FALSE)
conf.lower.vector <- z.value.vector[rej.hypo.vec.index] - Z.value
conf.upper.vector <- z.value.vector[rej.hypo.vec.index] + Z.value
returns <- list()
df <- data.frame(test.index = rej.hypo.vec.index,
z.value = z.value.vector[rej.hypo.vec.index],
conf.lower = conf.lower.vector,
conf.upper = conf.upper.vector,
p.value = p.value.vector[rej.hypo.vec.index],
p.value.adjusted = p.value.vector.adjusted[rej.hypo.vec.index]
)
returns$rejection.conf.int <- df
returns$rej.hypo.vec <- rej.hypo.vec
returns$num.reject <- R
returns$rej.hypo.vec.index <- rej.hypo.vec.index
return(returns)
}
# Test with simulated z
num.rep <- 100
num.test <- 1000
#Numbers of non-null
num.non.null <- floor(num.test/10)
#Numbers of null
num.null <- num.test - num.non.null
# false discovery proportion vector
fdp <- rep(NA,num.rep )
# false coverage proportion vector
fcp <- rep(NA,num.rep )
for (i in 1:num.rep) {
# Z-value with true mu = 0
z.null <- rnorm(num.null)
# Z-value with true mu != 0
non.null.true <- rnorm(num.non.null, mean=-3,sd=1)
z.non.null <- non.null.true + rnorm(num.non.null)
# Z-value vector
z <- c(z.null, z.non.null)
z.true <- c(rep(0,num.null), non.null.true)
z.true.01 <- c(rep(0,num.null), rep(1, num.non.null))
# Test example
test <- multiple_testing(z, q.level=0.1, method="BH") # choose BH since tests are independently generated
#False discovery proportion
fp <- sum(test$rej.hypo.vec==1 & z.true.01==0)
fdp[i] <- mean( fp / max(1,test$num.reject))
#False coverage proportion
fcp[i] <- mean(sum((test$rejection.conf.int$conf.lower > z.true[test$rej.hypo.vec.index]) |
(test$rejection.conf.int$conf.upper < z.true[test$rej.hypo.vec.index])) / max(1,test$num.reject))
}
#False discovery rate is average of false discovery proportion
fdr <- mean(fdp)
fdr
#False coverage rate is average of false coverage proportion
mean(fcp)
# FDR and FCR should be smaller than q.level (slightly violation may due to monte carlo error)
# test$num.reject
# plot(fdp, fcp)
# abline(0, 1)
multiple_testing <- function(z.value.vector, q.level = 0.05, method=c("BY", "BH")) {
# Get p-values vector
p.value.vector <- 2*pnorm(abs(z.value.vector), lower.tail = F)
num.test <- length(p.value.vector)
# Get adjusted p-values vector
p.value.vector.adjusted <- p.adjust(p.value.vector, method=method)
# Rejected hypotheses vector
rej.hypo.vec <- p.value.vector.adjusted < q.level
rej.hypo.vec.index <- which(rej.hypo.vec == 1)
# Number of rejection
R <- sum(rej.hypo.vec)
# Z.value for confidence interval
Z.value <- qnorm(1 - R*q.level/num.test, mean = 0, sd = 1, lower.tail = TRUE, log.p = FALSE)
conf.lower.vector <- z.value.vector[rej.hypo.vec.index] - Z.value
conf.upper.vector <- z.value.vector[rej.hypo.vec.index] + Z.value
returns <- list()
df <- data.frame(test.index = rej.hypo.vec.index,
z.value = z.value.vector[rej.hypo.vec.index],
conf.lower = conf.lower.vector,
conf.upper = conf.upper.vector,
p.value = p.value.vector[rej.hypo.vec.index],
p.value.adjusted = p.value.vector.adjusted[rej.hypo.vec.index]
)
returns$rejection.conf.int <- df
returns$rej.hypo.vec <- rej.hypo.vec
returns$num.reject <- R
returns$rej.hypo.vec.index <- rej.hypo.vec.index
return(returns)
}
# Test with simulated z
num.rep <- 100
num.test <- 1000
#Numbers of non-null
num.non.null <- floor(num.test/10)
#Numbers of null
num.null <- num.test - num.non.null
# false discovery proportion vector
fdp <- rep(NA,num.rep )
# false coverage proportion vector
fcp <- rep(NA,num.rep )
for (i in 1:num.rep) {
# Z-value with true mu = 0
z.null <- rnorm(num.null)
# Z-value with true mu != 0
non.null.true <- rnorm(num.non.null, mean=-3,sd=1)
z.non.null <- non.null.true + rnorm(num.non.null)
# Z-value vector
z <- c(z.null, z.non.null)
z.true <- c(rep(0,num.null), non.null.true)
z.true.01 <- c(rep(0,num.null), rep(1, num.non.null))
# Test example
test <- multiple_testing(z, q.level=0.1, method="BH") # choose BH since tests are independently generated
#False discovery proportion
fp <- sum(test$rej.hypo.vec==1 & z.true.01==0)
fdp[i] <- mean( fp / max(1,test$num.reject))
#False coverage proportion
fcp[i] <- mean(sum((test$rejection.conf.int$conf.lower > z.true[test$rej.hypo.vec.index]) |
(test$rejection.conf.int$conf.upper < z.true[test$rej.hypo.vec.index])) / max(1,test$num.reject))
}
#False discovery rate is average of false discovery proportion
fdr <- mean(fdp)
fdr
#False coverage rate is average of false coverage proportion
mean(fcp)
# FDR and FCR should be smaller than q.level (slightly violation may due to monte carlo error)
# test$num.reject
# plot(fdp, fcp)
# abline(0, 1)
multiple_testing <- function(z.value.vector, q.level = 0.05, method=c("BY", "BH")) {
# Get p-values vector
p.value.vector <- 2*pnorm(abs(z.value.vector), lower.tail = F)
num.test <- length(p.value.vector)
# Get adjusted p-values vector
p.value.vector.adjusted <- p.adjust(p.value.vector, method=method)
# Rejected hypotheses vector
rej.hypo.vec <- p.value.vector.adjusted < q.level
rej.hypo.vec.index <- which(rej.hypo.vec == 1)
# Number of rejection
R <- sum(rej.hypo.vec)
# Z.value for confidence interval
Z.value <- qnorm(1 - R*q.level/num.test, mean = 0, sd = 1, lower.tail = TRUE, log.p = FALSE)
conf.lower.vector <- z.value.vector[rej.hypo.vec.index] - Z.value
conf.upper.vector <- z.value.vector[rej.hypo.vec.index] + Z.value
returns <- list()
df <- data.frame(test.index = rej.hypo.vec.index,
z.value = z.value.vector[rej.hypo.vec.index],
conf.lower = conf.lower.vector,
conf.upper = conf.upper.vector,
p.value = p.value.vector[rej.hypo.vec.index],
p.value.adjusted = p.value.vector.adjusted[rej.hypo.vec.index]
)
returns$rejection.conf.int <- df
returns$rej.hypo.vec <- rej.hypo.vec
returns$num.reject <- R
returns$rej.hypo.vec.index <- rej.hypo.vec.index
return(returns)
}
# Test with simulated z
num.rep <- 100
num.test <- 1000
#Numbers of non-null
num.non.null <- floor(num.test/10)
#Numbers of null
num.null <- num.test - num.non.null
# false discovery proportion vector
fdp <- rep(NA,num.rep )
# false coverage proportion vector
fcp <- rep(NA,num.rep )
for (i in 1:num.rep) {
# Z-value with true mu = 0
z.null <- rnorm(num.null)
# Z-value with true mu != 0
non.null.true <- rnorm(num.non.null, mean=-3,sd=1)
z.non.null <- non.null.true + rnorm(num.non.null)
# Z-value vector
z <- c(z.null, z.non.null)
z.true <- c(rep(0,num.null), non.null.true)
z.true.01 <- c(rep(0,num.null), rep(1, num.non.null))
# Test example
test <- multiple_testing(z, q.level=0.1, method="BH") # choose BH since tests are independently generated
#False discovery proportion
fp <- sum(test$rej.hypo.vec==1 & z.true.01==0)
fdp[i] <- mean( fp / max(1,test$num.reject))
#False coverage proportion
fcp[i] <- mean(sum((test$rejection.conf.int$conf.lower > z.true[test$rej.hypo.vec.index]) |
(test$rejection.conf.int$conf.upper < z.true[test$rej.hypo.vec.index])) / max(1,test$num.reject))
}
#False discovery rate is average of false discovery proportion
fdr <- mean(fdp)
fdr
#False coverage rate is average of false coverage proportion
mean(fcp)
# FDR and FCR should be smaller than q.level (slightly violation may due to monte carlo error)
# test$num.reject
# plot(fdp, fcp)
# abline(0, 1)
cranlogs::cran_downloads("robsel", "last-month")
cranlogs::cran_downloads("robsel", "last-month")
cranlogs::cran_downloads("robsel", "last-month")
sum(cranlogs::cran_downloads("robsel", "last-month")$count)
cranlogs::cran_downloads("robsel", "last-month")
cranlogs::cran_downloads("robsel", "last-month")
cranlogs::cran_downloads("robsel")
cranlogs::cran_downloads("robsel", "last-month")
diff(1:3)
test = rnorm(10)
1/(101)
1- 0.05
1- 0.05 + 1/10
1- 0.05 + 1/50
1- 0.05 + 1/60
tanh(atanh(0.5))
?tanh
library(splines)
?bs
cranlogs::cran_downloads("robsel")
cranlogs::cran_downloads("robsel", "last-month")
cranlogs::cran_downloads("robsel", "last-month")
cranlogs::cran_downloads("robsel", "last-month")
cranlogs::cran_downloads("robsel", "last-month")
cranlogs::cran_downloads("robsel", "last-month")
cranlogs::cran_downloads("robsel", "last-month")
cranlogs::cran_downloads("robsel", "last-month")
cranlogs::cran_downloads("robsel", )
cranlogs::cran_downloads("robsel")
sum(cranlogs::cran_downloads("robsel", "last-month")$count)
cranlogs::cran_downloads("robsel", "last-month")
cranlogs::cran_downloads("robsel", "last-month")
cranlogs::cran_downloads("robsel", "last-month")
exp(1) / (1+exp(1))
logistic(1)
log(1+exp(1))
cranlogs::cran_downloads("robsel", "last-month")
sqrt(0.9 * 2)
sqrt(1.8)
exp(-1e-5)
exp(-0)
exp(-0000000)
exp(-22222222)
exp(1e-5)
exp(-1e-5)
exp(-1e-5*20)
exp(-1e-4*20)
exp(-1e-4*40)
exp(-1e-4*1:40)
exp(-0)
23/25
test = bs(rep(1:10, times=5), df=10, intercept=TRUE)
library(splines)
test = bs(rep(1:10, times=5), df=10, intercept=TRUE)
test
rep(1:10, times=5)
test = bs(rep(1:10, times=5), df=20, intercept=TRUE)
test
test = bs(rep(1:10, times=5), df=10, intercept=TRUE)
test
test
?bs
test.knots
test.knots()
knots(test)
test
test = bs(rep(1:10, times=1), df=10, intercept=TRUE)
test
dim(test)
test = bs(rep(1:10, times=1), df=20, intercept=TRUE)
test
library(waveslim)
?moddwtY
?moddwtY
moddwt
?moddwtY
?moddwt
?modwt
?brick.wall
res <- list()
res$beta <- rnorm(4)
length(res$beta)
####
setwd("~/Downloads/truncatedFGLM_Rcode_withCpp/linearCase")
library(ggplot2)
library(Rcpp)
####
setwd("~/Downloads/truncatedFGLM_Rcode_withCpp/linearCase")
source("truncatedLinearModel.R")
####
##########################################################################################
# case 1, linear model, sample size n = 400, nbasis = 50
##########################################################################################
n = 800
nbasis = 50
seed = 1234
##########################################################################################
####                                generate data function                            ####
#################################################a#########################################
generateAR1 <- function(q, sd = 3) {
coeff = rep(999, q)
coeff[1] = rnorm(1, sd = sd)
for (i in 2:q) {
coeff[i] = rnorm(1, mean = coeff[i-1], sd = sd)
}
return(coeff)
}
#########                  generate beta with 18 bspline basis                    #########
denseGrid = seq(0, 1, length.out = 101)
eval_grid = denseGrid[-1] - 0.01/2
knots18 <- seq(0, 1, length.out = 16)[c(-1,-16)] # the interior 14 knots
bs.18<- bSpline(denseGrid, knots = knots18, degree = 3, intercept = T)
eta_true1 =  c(-0.45, -0.29, -1.79, -3.08, -2.11,  0.64,  5.72,  3.02, rep(0, 10))
bs.18.100 = predict(bs.18, newx = eval_grid)
beta_true1 = bs.18 %*% eta_true1
beta_true1.100 = bs.18.100 %*% eta_true1
plot(beta_true1.100, type = 'l', main = 'coefficient beta function - case 1')
generateCase1a <- function(seed, n = 400) {
#########                    generate X with 30 bspline basis                    #########
denseGrid = seq(0, 1, length.out = 101)
knots30 <- seq(0, 1, length.out = 28)[c(-1,-28)] # the interior 26 knots
# NO. of basis = order + No. interior knots = 4 + 16 = 20
bs.30 <- bSpline(denseGrid, knots = knots30, degree = 3, intercept = T)
bs.30.100 <- predict(bs.30, newx = eval_grid)
set.seed(seed) # seed = 3
basis.coef = sapply(1:n, function(i) generateAR1(q = 30)/sqrt((1:30)))
dt = 0.01
Xcurves = t(bs.30 %*% basis.coef)
Xcurves.100 = t(bs.30.100 %*% basis.coef)
#########                         generate Y, n x 1 vector                       #########
set.seed(seed)
Y = 1 + Xcurves.100 %*% beta_true1.100 *dt  + rnorm(n, sd = 1)
# the SN ratio
SNratio = var(Xcurves %*% beta_true1 *dt)/var(Y)
return(list(
Xcurves = Xcurves,
Y = Y,
SNratio = SNratio
))
}
##########################################################################################
####                              solve the truncated model                           ####
##########################################################################################
sample_linear = generateCase1a(seed = seed, n = n)
Y = sample_linear$Y
Xcurves = sample_linear$Xcurves
print(paste0('signal to noise ratio is: ', round(sample_linear$SNratio, 2)))
time <- proc.time()
res_list_Cpp = truncatedLinearModelCpp(Y, Xcurves, denseGrid, nbasis = nbasis, precision = 1e-5)
time <- proc.time() - time
time
setwd("~/truncatedFGLM/R")
